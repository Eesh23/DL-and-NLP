{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbcc9QS1tnBN"
   },
   "source": [
    "**ASSIGNMENT 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2Eeke4Z_EkW"
   },
   "source": [
    "Group Name: Group 81\n",
    "Member Names: Ishan Phadte and Eeshaan Patel\n",
    "Member Student Numbers: 300238878 and 300165634\n",
    "Report Title: CSI 4106 A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMUnCICdyBbs"
   },
   "source": [
    "**Derived Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-so3pwbPKTDX"
   },
   "source": [
    "This notebook is a starting point for Assignment 4. In this assignment, you will perform a classification empirical study. This notebook will help you to create derived datasets in Section 2 of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhFvS3q7Lu0R",
    "outputId": "aa0e3c61-ea58-4d1b-953b-b481370731d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/homebrew/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from spacy) (68.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/homebrew/lib/python3.11/site-packages (from spacy) (1.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /opt/homebrew/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/homebrew/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/homebrew/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/homebrew/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "#let's start by installing spaCy\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aCWgl6PLKTDY"
   },
   "outputs": [],
   "source": [
    "#NLP Library\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#print('Hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX9WQWGSwU2D"
   },
   "source": [
    "You have been given a list of datasets in the assignment description. Choose one of the datasets and provide the link below and read the dataset using pandas. You should provide a link to your own Github repository even if you are using a reduced version of a dataset from your TA's repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSyg0jjC1jJa"
   },
   "source": [
    "add description of the dataset and your justification of the choices made to obtain the derived datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1Xx4qMCLKTDb"
   },
   "outputs": [],
   "source": [
    "#Load the dataset you chose.\n",
    "# Make sure the Notebook can load your dataset, just like previous assignments.\n",
    "\n",
    "#url = 'https://raw.githubusercontent.com/baharin/CSI4106-Assignment4-Datasets/main/reduced_file_cnnnews.csv'\n",
    "# url = 'https://raw.githubusercontent.com/baharin/CSI4106-Assignment4-Datasets/main/reduced_drugsComTest_raw_fiveclasses.csv'\n",
    "url = 'https://raw.githubusercontent.com/IshanPhadte776/CSI4106A4/main/reduced_file_AirPassengerReviews.csv'\n",
    "\n",
    "#provide the link to the raw version of dataset. You *need* to provide a link to *your own* github repository. DO NOT use the link that is provided as an example.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wg24OUV81Xgm",
    "outputId": "1724e55e-07e6-4be1-800a-24a3a3c0e902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/IshanPhadte776/CSI4106A4/main/reduced_file_AirPassengerReviews.csv\n"
     ]
    }
   ],
   "source": [
    "print(url)\n",
    "#data = pd.read_csv(url)\n",
    "data = pd.read_csv(url, nrows=int(0.5 * pd.read_csv(url).shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AQ5nSY1HKTDd",
    "outputId": "d7b9ac0f-1501-4e91-a9a2-32494278bda9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_review</th>\n",
       "      <th>NPS Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London to Izmir via Istanbul. First time I'd ...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Istanbul to Bucharest. We make our check in i...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rome to Prishtina via Istanbul. I flew with t...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flew on Turkish Airlines IAD-IST-KHI and retu...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mumbai to Dublin via Istanbul. Never book Tur...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     customer_review  NPS Score\n",
       "0   London to Izmir via Istanbul. First time I'd ...    Passive\n",
       "1   Istanbul to Bucharest. We make our check in i...  Detractor\n",
       "2   Rome to Prishtina via Istanbul. I flew with t...  Detractor\n",
       "3   Flew on Turkish Airlines IAD-IST-KHI and retu...   Promoter\n",
       "4   Mumbai to Dublin via Istanbul. Never book Tur...  Detractor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3pycllPKTDd"
   },
   "source": [
    "This is where you create the NLP pipeline. load() will download the correct model (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wQtSi8XuKTDe"
   },
   "outputs": [],
   "source": [
    "#Loads the English-Trained Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccqFArDyKTDf"
   },
   "source": [
    "Applying the pipeline to every sentences creates a Document where every word is a Token object.\n",
    "\n",
    "Doc: https://spacy.io/api/doc\n",
    "\n",
    "Token: https://spacy.io/api/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcaeMUL2KTDg"
   },
   "outputs": [],
   "source": [
    "#Apply nlp pipeline to the column that has your sentences.\n",
    "data['tokenized'] = data['customer_review'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7i6ai1I8KTDg",
    "outputId": "5a56d0d1-0c8f-44c4-9d5a-59242180fc7f"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHRfZ2uEKTDh"
   },
   "source": [
    "A Token object has many attributes such as part-of-speech (pos_), lemma (lemma_), etc. Take a look at the documentation to see all attributes.\n",
    "\n",
    "The following function is an example on how you can fetch a specific pos tagging from a sentence. We return the lemmatization because we only want the infinitive word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qw0a_2ySyUo2"
   },
   "outputs": [],
   "source": [
    "#create empty dataframes that will store your derived datasets\n",
    "\n",
    "\n",
    "#Creates with two columns, Class which is blank and pos\n",
    "derived_dataset1 = pd.DataFrame(columns = ['Class', 'pos'])\n",
    "derived_dataset2 = pd.DataFrame(columns = ['Class', 'pos-np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Yeak1tAOKTDi"
   },
   "outputs": [],
   "source": [
    "def get_pos(sentence, wanted_pos): #wanted_pos refers to the desired pos tagging\n",
    "    verbs = []\n",
    "    for token in sentence:\n",
    "        if token.pos_ in wanted_pos:\n",
    "            verbs.append(token.lemma_) # lemma returns a number. lemma_ return a string\n",
    "    return ' '.join(verbs) # return value is as a string and not a list for countVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rtgrIQp4PkHu"
   },
   "outputs": [],
   "source": [
    "def extract_entities_and_pos(doc, entity_types=['LOC'], pos_tags=['NOUN', 'ADJ']):\n",
    "    entities = [ent.text for ent in doc.ents if ent.label_ in entity_types]\n",
    "    selected_pos = [token.text for token in doc if token.pos_ in pos_tags]\n",
    "\n",
    "    # Combine entities and selected POS into a single list or string\n",
    "    result = entities + selected_pos\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "147NRzwKKTDj"
   },
   "outputs": [],
   "source": [
    "#As an example, we use the above function to fetch all the verbs. We store this information in our first derived dataset\n",
    "derived_dataset1['Class'] = data['NPS Score']\n",
    "derived_dataset1['pos'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['ADJ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "G_bUg_fVKTDk",
    "outputId": "aa7640bc-e444-4b6a-8543-17369bb7e1f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6ce76bc0-ead8-4533-8596-2ea74e2b43bf\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passive</td>\n",
       "      <td>first good nice great Most contradictory littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>first last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>several past bad bad normal most useless few w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promoter</td>\n",
       "      <td>excellent inflight extensive easy excellent in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>turkish other more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ce76bc0-ead8-4533-8596-2ea74e2b43bf')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6ce76bc0-ead8-4533-8596-2ea74e2b43bf button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6ce76bc0-ead8-4533-8596-2ea74e2b43bf');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-5d0daa13-dd69-450e-8e5f-cba2056fe6ea\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d0daa13-dd69-450e-8e5f-cba2056fe6ea')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-5d0daa13-dd69-450e-8e5f-cba2056fe6ea button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Class                                                pos\n",
       "0    Passive  first good nice great Most contradictory littl...\n",
       "1  Detractor                                         first last\n",
       "2  Detractor  several past bad bad normal most useless few w...\n",
       "3   Promoter  excellent inflight extensive easy excellent in...\n",
       "4  Detractor                                 turkish other more"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AuGv-NnfKTDj",
    "outputId": "403f9ba3-d79f-495c-fbda-866054e77cdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8b933dd5-f18e-46ac-b1e6-5c619af58f60\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos-np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passive</td>\n",
       "      <td>[London, Istanbul, Istanbul, Ukraine, London, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>[Istanbul, check, airport, luggage, gate, gate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>[Rome, Prishtina, Istanbul, Rome, Prishtina, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promoter</td>\n",
       "      <td>[quality, flights, time, catering, excellent, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>[Mumbai, Dublin, Istanbul, Dublin, Mumbai, Mum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b933dd5-f18e-46ac-b1e6-5c619af58f60')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8b933dd5-f18e-46ac-b1e6-5c619af58f60 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8b933dd5-f18e-46ac-b1e6-5c619af58f60');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c8d1a02b-d259-4409-953d-e1f1eac60282\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8d1a02b-d259-4409-953d-e1f1eac60282')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c8d1a02b-d259-4409-953d-e1f1eac60282 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Class                                             pos-np\n",
       "0    Passive  [London, Istanbul, Istanbul, Ukraine, London, ...\n",
       "1  Detractor  [Istanbul, check, airport, luggage, gate, gate...\n",
       "2  Detractor  [Rome, Prishtina, Istanbul, Rome, Prishtina, I...\n",
       "3   Promoter  [quality, flights, time, catering, excellent, ...\n",
       "4  Detractor  [Mumbai, Dublin, Istanbul, Dublin, Mumbai, Mum..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change this line to fetch your desired pos taggings for the second derived dataset\n",
    "#derived_dataset2['pos-np'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['PRON']))\n",
    "derived_dataset2['Class'] = data['NPS Score']\n",
    "derived_dataset2['pos-np'] = data['tokenized'].apply(lambda doc: extract_entities_and_pos(doc, entity_types=['GPE'], pos_tags=['NOUN', 'ADJ']))\n",
    "\n",
    "derived_dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NR7AdW0MfXO6",
    "outputId": "20fee4ca-e2c7-4c90-b857-5aad71fc0ce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "#For Derived Dataset 2, you also need to include Named Entities\n",
    "#Below is just an example of obtaining such entities on a specific sentence, but you would do NER\n",
    "#on the dataset of your choice.\n",
    "#You can choose the types of entities (dates, organization, people) that you want,\n",
    "#and then in your derived dataset, just make sure you include these entities separated by spaces (as shown for verbs)\n",
    "#in a previous cell.\n",
    "\n",
    "sentence = \"apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pX4RgKhKTDk"
   },
   "source": [
    "Now that you have your derived datasets, you can move to perform your classificaton task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GhniwHtzfQt"
   },
   "source": [
    "**Perform A Classification Empirical Study**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcjwo1A4PkHv"
   },
   "source": [
    "1. Encode the text as input features with associated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "42B6odhUPkHv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#derived_dataset2['pos-np'] = derived_dataset2['pos-np'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Step 1: Create a CountVectorizer with optional stop words\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "#X_features_tf = vectorizer.fit_transform(derived_dataset2['pos-np'])\n",
    "\n",
    "\n",
    "# Original Dataset\n",
    "x = vectorizer.fit_transform(data['tokenized'].apply(lambda x: ' '.join([token.text for token in x])))\n",
    "y = data['NPS Score']\n",
    "# Derived-Dataset-1\n",
    "x_derived1 = vectorizer.transform(derived_dataset1['pos'].apply(lambda x: ' '.join(x.split())))\n",
    "y_derived1 = derived_dataset1['Class']\n",
    "# Derived-Dataset-2\n",
    "x_derived2 = vectorizer.transform(derived_dataset2['pos-np'].apply(lambda x: ' '.join(map(str, x))))\n",
    "y_derived2 = derived_dataset2['Class']\n",
    "\n",
    "\n",
    "#print(X_features_tf)\n",
    "#print(x_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZ6Wm-u3PkHv"
   },
   "source": [
    "2. Define 2 models using some default parameters\n",
    "3. Train/test/evaluate your 2 models(that have default parameters) on your 3 datasets. For each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCkB2u0fPkHw",
    "outputId": "e217643b-1fc6-43eb-8f1a-c8e42fd2f9a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7230\n",
      "Recall (Micro): 0.7230\n",
      "Precision (Macro): 0.6686\n",
      "Recall (Macro): 0.6669\n"
     ]
    }
   ],
   "source": [
    "#Case 1\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Create a Logistic Regression model with specific parameters\n",
    "logreg_model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBHhdkhea9DQ",
    "outputId": "4188aca0-1690-46b9-c5fc-1e9363bbe2a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7123\n",
      "Recall (Micro): 0.7123\n",
      "Precision (Macro): 0.6485\n",
      "Recall (Macro): 0.6446\n"
     ]
    }
   ],
   "source": [
    "#Case 2\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Create a Logistic Regression model with specific parameters\n",
    "logreg_model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x_derived1):\n",
    "    X_train, X_test = x_derived1[train_index], x_derived1[test_index]\n",
    "    y_train, y_test = y_derived1.iloc[train_index], y_derived1.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhiUL0bFa9Mj",
    "outputId": "773f704b-1c5c-4b84-8d15-c2b08d8d920f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7006\n",
      "Recall (Micro): 0.7006\n",
      "Precision (Macro): 0.6423\n",
      "Recall (Macro): 0.6414\n"
     ]
    }
   ],
   "source": [
    "#Case 3\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Create a Logistic Regression model with specific parameters\n",
    "logreg_model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x_derived2):\n",
    "    X_train, X_test = x_derived2[train_index], x_derived2[test_index]\n",
    "    y_train, y_test = y_derived2.iloc[train_index], y_derived2.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXqjqBhZPkHw",
    "outputId": "f252194f-4744-4b9b-ee69-89aa120b1f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7223\n",
      "Recall (Micro): 0.7223\n",
      "Precision (Macro): 0.6623\n",
      "Recall (Macro): 0.6591\n"
     ]
    }
   ],
   "source": [
    "# Create an MLP model with specific parameters\n",
    "#Case 4\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWlBo-MxPkHw",
    "outputId": "be914013-4551-4491-8636-c10e64f5c69d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7323\n",
      "Recall (Micro): 0.7323\n",
      "Precision (Macro): 0.6251\n",
      "Recall (Macro): 0.6276\n"
     ]
    }
   ],
   "source": [
    "#Case 5\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLP model with specific parameters\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x_derived1):\n",
    "    X_train, X_test = x_derived1[train_index], x_derived1[test_index]\n",
    "    y_train, y_test = y_derived1.iloc[train_index], y_derived1.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jcimt5LjPkHw",
    "outputId": "b31261ca-86ae-477b-9c57-cbc924499f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7751\n",
      "Recall (Micro): 0.7751\n",
      "Precision (Macro): 0.6654\n",
      "Recall (Macro): 0.6506\n"
     ]
    }
   ],
   "source": [
    "#Case 6\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLP model with specific parameters\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x_derived2):\n",
    "    X_train, X_test = x_derived2[train_index], x_derived2[test_index]\n",
    "    y_train, y_test = y_derived2.iloc[train_index], y_derived2.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cy9D3ViPkHx"
   },
   "source": [
    "4. Modify some parameters of the MLP model and perform a train/test/evaluate again. Do this\n",
    "for two times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhCj5WgNPkHx"
   },
   "source": [
    "5. Analyze the obtained results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qM6enWwLPkHx",
    "outputId": "73a5c3b6-7b87-4a3e-86b1-3753afcfe24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7788\n",
      "Recall (Micro): 0.7788\n",
      "Precision (Macro): 0.6499\n",
      "Recall (Macro): 0.6431\n"
     ]
    }
   ],
   "source": [
    "#Case 7\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Create an MLP model with specific parameters\n",
    "mod_mlp_model = MLPClassifier(max_iter=500, hidden_layer_sizes=(100,))\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mod_mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mod_mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6b_-lp0PkHy",
    "outputId": "f742f5e9-1e38-410e-f2cb-74b972ccda44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7258\n",
      "Recall (Micro): 0.7258\n",
      "Precision (Macro): 0.6183\n",
      "Recall (Macro): 0.6150\n"
     ]
    }
   ],
   "source": [
    "#Case 8\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLP model with specific parameters\n",
    "mod_mlp_model = MLPClassifier(max_iter=500, hidden_layer_sizes=(100,))\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x_derived1):\n",
    "    X_train, X_test = x_derived1[train_index], x_derived1[test_index]\n",
    "    y_train, y_test = y_derived1.iloc[train_index], y_derived1.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mod_mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mod_mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2o8cUgQCPkHy",
    "outputId": "ed667fcd-50af-4e14-a60e-120947df3568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.6859\n",
      "Recall (Micro): 0.6859\n",
      "Precision (Macro): 0.6287\n",
      "Recall (Macro): 0.6285\n"
     ]
    }
   ],
   "source": [
    "#Case 9\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLP model with specific parameters\n",
    "mod_mlp_model = MLPClassifier(max_iter=500, hidden_layer_sizes=(100,))\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x_derived2):\n",
    "    X_train, X_test = x_derived2[train_index], x_derived2[test_index]\n",
    "    y_train, y_test = y_derived2.iloc[train_index], y_derived2.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mod_mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mod_mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BzCrciqPkHy",
    "outputId": "e27f09c4-223b-4b08-dd40-104ffebb460c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7203\n",
      "Recall (Micro): 0.7203\n",
      "Precision (Macro): 0.6564\n",
      "Recall (Macro): 0.6549\n"
     ]
    }
   ],
   "source": [
    "#Case 10\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLP model with specific parameters\n",
    "mod_mlp_model = MLPClassifier(max_iter=500, activation='tanh')\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mod_mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mod_mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4_fkxbiPkIC",
    "outputId": "08c3c93d-30f3-4cfe-839d-4e81c09dc5ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.6212\n",
      "Recall (Micro): 0.6212\n",
      "Precision (Macro): 0.6484\n",
      "Recall (Macro): 0.5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "#Case 11\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLP model with specific parameters\n",
    "mod_mlp_model = MLPClassifier(max_iter=500, activation='relu')\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x_derived1):\n",
    "    X_train, X_test = x_derived1[train_index], x_derived1[test_index]\n",
    "    y_train, y_test = y_derived1.iloc[train_index], y_derived1.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mod_mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mod_mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaOLefk3PkIC",
    "outputId": "9ad678e6-a653-4afb-b48f-6ff017a0ca65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Micro): 0.7100\n",
      "Recall (Micro): 0.7100\n",
      "Precision (Macro): 0.6537\n",
      "Recall (Macro): 0.6481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Case 12\n",
    "#Create an MLP model with specific parameters\n",
    "mod_mlp_model = MLPClassifier(max_iter=500, activation='relu')\n",
    "\n",
    "# Define the number of splits for KFold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "# Lists to store precision and recall values for each fold\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "\n",
    "# Iterate through folds\n",
    "for train_index, test_index in kf.split(x_derived2):\n",
    "    X_train, X_test = x_derived2[train_index], x_derived2[test_index]\n",
    "    y_train, y_test = y_derived2.iloc[train_index], y_derived2.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    mod_mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mod_mlp_model.predict(X_test)\n",
    "\n",
    "    # Calculate precision and recall for each fold\n",
    "    precision_micro.append(precision_score(y_test, y_pred, average='micro', zero_division=1))\n",
    "    recall_micro.append(recall_score(y_test, y_pred, average='micro'))\n",
    "    precision_macro.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_macro.append(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate average precision and recall across folds\n",
    "avg_precision_micro = np.mean(precision_micro)\n",
    "avg_recall_micro = np.mean(recall_micro)\n",
    "avg_precision_macro = np.mean(precision_macro)\n",
    "avg_recall_macro = np.mean(recall_macro)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision (Micro): {avg_precision_micro:.4f}\")\n",
    "print(f\"Recall (Micro): {avg_recall_micro:.4f}\")\n",
    "print(f\"Precision (Macro): {avg_precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {avg_recall_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6usbm1CBRxWr"
   },
   "source": [
    "Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JXol1xmR8DV"
   },
   "source": [
    "\n",
    "\n",
    "1.   Logistic Regression on Original Dataset\n",
    "\n",
    "Precision (Micro): 0.7230\n",
    "Recall (Micro): 0.7230\n",
    "Precision (Macro): 0.6686\n",
    "Recall (Macro): 0.6669\n",
    "\n",
    "2.   Logistic Regression on Dervied Dataset 1\n",
    "\n",
    "Precision (Micro): 0.7123\n",
    "Recall (Micro): 0.7123\n",
    "Precision (Macro): 0.6485\n",
    "Recall (Macro): 0.6446\n",
    "\n",
    "3.   Logistic Regression on Dervied Dataset 2\n",
    "\n",
    "Precision (Micro): 0.7006\n",
    "Recall (Micro): 0.7006\n",
    "Precision (Macro): 0.6423\n",
    "Recall (Macro): 0.6414\n",
    "\n",
    "4.   MLP Base on Original Dataset\n",
    "\n",
    "Precision (Micro): 0.7223\n",
    "Recall (Micro): 0.7223\n",
    "Precision (Macro): 0.6623\n",
    "Recall (Macro): 0.6591\n",
    "\n",
    "\n",
    "5.   MLP Base on Dervied Dataset 1\n",
    "\n",
    "Precision (Micro): 0.7323\n",
    "Recall (Micro): 0.7323\n",
    "Precision (Macro): 0.6251\n",
    "Recall (Macro): 0.6276\n",
    "\n",
    "6.   MLP Base on Dervied Dataset 2\n",
    "\n",
    "Precision (Micro): 0.7751\n",
    "Recall (Micro): 0.7751\n",
    "Precision (Macro): 0.6654\n",
    "Recall (Macro): 0.6506\n",
    "\n",
    "7.   MLP HLS on Original Dataset\n",
    "\n",
    "Precision (Micro): 0.7788\n",
    "Recall (Micro): 0.7788\n",
    "Precision (Macro): 0.6499\n",
    "Recall (Macro): 0.6431\n",
    "\n",
    "\n",
    "8.   MLP HLS on Dervied Dataset 1\n",
    "\n",
    "Precision (Micro): 0.7258\n",
    "Recall (Micro): 0.7258\n",
    "Precision (Macro): 0.6183\n",
    "Recall (Macro): 0.6150\n",
    "\n",
    "9.   MLP HLS on Dervied Dataset 2\n",
    "\n",
    "Precision (Micro): 0.6859\n",
    "Recall (Micro): 0.6859\n",
    "Precision (Macro): 0.6287\n",
    "Recall (Macro): 0.6285\n",
    "\n",
    "10.  MLP Activation on Original Dataset\n",
    "\n",
    "Precision (Micro): 0.7203\n",
    "Recall (Micro): 0.7203\n",
    "Precision (Macro): 0.6564\n",
    "Recall (Macro): 0.6549\n",
    "\n",
    "\n",
    "11.  MLP Activation on Dervied Dataset 1\n",
    "\n",
    "Precision (Micro): 0.6212\n",
    "Recall (Micro): 0.6212\n",
    "Precision (Macro): 0.6484\n",
    "Recall (Macro): 0.5499\n",
    "\n",
    "12.  MLP Activation on Dervied Dataset 2\n",
    "\n",
    "Precision (Micro): 0.7100\n",
    "Recall (Micro): 0.7100\n",
    "Precision (Macro): 0.6537\n",
    "Recall (Macro): 0.6481\n",
    "\n",
    "\n",
    "For Logistic Regression, The models performs better on the original dataset compared to the deprived data set\n",
    "\n",
    "For the Base MLP Set, the model performs best on the Deprived Data Set 2\n",
    "\n",
    "For the HLS Model, the model performs best on the original model\n",
    "\n",
    "For the Activitation Model, the model performs best on the original and DD2 and worst on DD1.\n",
    "\n",
    "Overall, Dataset 1 was ineffective and Data Set 2 and the original data was helpful.\n",
    "\n",
    "The MLP HLS on the original dataset was the best."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
